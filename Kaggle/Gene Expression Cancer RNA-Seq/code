import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import time

# Обработка данных: отбор и стандартизация
from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.decomposition import PCA

# Метрики
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score

# Модели
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

from xgboost import XGBClassifier
from sklearn.neural_network import MLPClassifier

# Пути к файлам 
data_path = '/kaggle/input/datasets/waalbannyantudre/gene-expression-cancer-rna-seq-donated-on-682016/data.csv' 
labels_path = '/kaggle/input/datasets/waalbannyantudre/gene-expression-cancer-rna-seq-donated-on-682016/labels.csv'

try:
    # Таблицы
    df = pd.read_csv(data_path)
    labels = pd.read_csv(labels_path)

    # Чистка от лишних колонок
    if 'Unnamed: 0' in df.columns:
        df.drop('Unnamed: 0', axis=1, inplace=True)
    if 'Unnamed: 0' in labels.columns:
        labels.drop('Unnamed: 0', axis=1, inplace=True)

    print(f"Размер данных: {df.shape}")
    print(f"Размер меток: {labels.shape}")

    # Проверка распределения опухолей в данных
    plt.figure(figsize=(8, 4))
    sns.countplot(x='Class', data=labels)
    plt.title('Распределение типов опухолей в датасете')
    plt.show()

except FileNotFoundError:
    print("ОШИБКА: Датасет не найден.")

# Перевод названий рака в числа для модели
le = LabelEncoder()
y = le.fit_transform(labels.iloc[:, 0])
X = df.values

# Отбор только тех генов, которые присутствуют не в каждом образце.
selector_var = VarianceThreshold(threshold=0.0)
X_var = selector_var.fit_transform(X)

# Отбор 3000 самых часто встречающихся генов (самых показательных)
k_best = 3000
selector_kbest = SelectKBest(score_func=f_classif, k=k_best)
X_selected = selector_kbest.fit_transform(X_var, y)

# Приводим к одному стандарту
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_selected)

# Сжимаем эти гены до двух колонок
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

plt.figure(figsize=(10, 6))
sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=le.inverse_transform(y), palette='viridis', s=50)
plt.title('Визуализация данных через PCA (2D проекция)')
plt.xlabel('Часть 1')
plt.ylabel('Часть 2')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

# Разделение данных на учебную и тестовую выборку
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, solver='lbfgs'),
    "Random Forest": RandomForestClassifier(n_estimators=200, random_state=42),

    "XGBoost": XGBClassifier(eval_metric='mlogloss', n_estimators=200),
    "MLP (Neural Net)": MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=500, alpha=0.01, random_state=42)
}

results_log = []

for name, model in models.items():
    start_time = time.time()
    model.fit(X_train, y_train)
    train_time = time.time() - start_time

    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='weighted')

    results_log.append({
        "Model": name,
        "Accuracy": acc,
        "F1-Score": f1,
        "Time (s)": round(train_time, 3)
    })

    print(f"{name}: Точность = {acc:.4f}, F1 = {f1:.4f} (время: {train_time:.2f}с)")

# Сортируем результаты от лучшего к худшему
results_df = pd.DataFrame(results_log).sort_values(by='F1-Score', ascending=False)

# Сравниваем модели по метрике F1 и рисуем график
plt.figure(figsize=(10, 5))
sns.barplot(x='F1-Score', y='Model', data=results_df, hue='Model', palette='magma', legend=False)
plt.title('Сравнение моделей по f1-score')
plt.xlim(0.8, 1.0)
plt.show()

# Выбираем лучшую модель делаем предсказания 
best_model_name = results_df.iloc[0]['Model']
best_model = models[best_model_name]
y_pred_best = best_model.predict(X_test)

# Строим матрицу ошибок этой модели
cm = confusion_matrix(y_test, y_pred_best)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.title(f'Матрица ошибок для лучшей модели: {best_model_name}')
plt.ylabel('Реальность')
plt.xlabel('Предсказание')
plt.show()

print(f"\nОтчёт по лучшей модели ({best_model_name}):")
print(classification_report(y_test, y_pred_best, target_names=le.classes_))
